import pyaudio
import json
import speech_recognition as sr
from vosk import Model, KaldiRecognizer
import wave
import os
from pydub import AudioSegment

def convert_audio(filepath):
    """ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ –≤ WAV (16 kHz, 16 –±–∏—Ç, –º–æ–Ω–æ) """
    audio = AudioSegment.from_file(filepath)
    audio = audio.set_channels(1).set_frame_rate(16000).set_sample_width(2)
    audio.export(filepath, format="wav")
    return filepath

def create_recognizer():
    model = Model("vosk-model-ru-0.42")
    recognizer = KaldiRecognizer(model, 16000)
    return recognizer

def analize_audio(recognizer, wf):
    try:
        print('–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞...')
        while True:
            data = wf.readframes(4000)
            if len(data) == 0:
                break
            if recognizer.AcceptWaveform(data):
                result = json.loads(recognizer.Result())
                text = result["text"]
                return text
    except Exception as e:
        print('e', e)

def get_audio_files(folder_path, recognizer):
    for file_name in os.listdir(folder_path):
        if file_name[-4:] == '.wav':
            file_path = os.path.join(folder_path, file_name)
            wf = wave.open(file_path, "rb")
            if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getframerate() != 16000:
                file_path = convert_audio(file_path)
                wf = wave.open(file_path, "rb")
                print('convert audio')
            print(file_path)
            text = analize_audio(recognizer, wf)
            print("–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞: ", text)

recognizer = ''
recognizer = create_recognizer()
get_audio_files('.', recognizer)


        
        
    # with open(path, 'r') as file:
    #     wf = wave.open("audio.wav", "rb")

# get_audio_files(".")

        

# # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
# 
# 

# # recognizer = KaldiRecognizer(model, 16000, '["–Ω–ø–≤", "–¥–¥—Ç", "–ó–ë–°", "–ö–ù–ë–ö", "–°–ü–û", "–ì–ò–°", "–û–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ –ë–£"]')

# # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º PyAudio
# mic = pyaudio.PyAudio()

# # üîπ –®—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é
# sr_recognizer = sr.Recognizer()
# with sr.Microphone() as source:
#     print("üîÑ –ü–æ–¥—Å—Ç—Ä–æ–π–∫–∞ –ø–æ–¥ –æ–∫—Ä—É–∂–∞—é—â–∏–π —à—É–º...")
#     sr_recognizer.adjust_for_ambient_noise(source, duration=2)  # –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –ø–æ —à—É–º—É

# # –û—Ç–∫—Ä—ã–≤–∞–µ–º –ø–æ—Ç–æ–∫ –¥–ª—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
# # stream = mic.open(format=pyaudio.paInt16, channels=1, rate=16000, 
# #                   input=True, frames_per_buffer=4000)
# # stream.start_stream()

# print("üé§ –ì–æ–≤–æ—Ä–∏—Ç–µ...")

# # –¶–∏–∫–ª —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
# # while True:
#     # data = stream.read(4000, exception_on_overflow=False)

#     # if recognizer.AcceptWaveform(data):
#     #     result = json.loads(recognizer.Result())
#     #     text = result["text"]
#     #     print("–í—ã —Å–∫–∞–∑–∞–ª–∏:", text)

#     #     if "—Å—Ç–æ–ø" in text:
#     #         print("‚èπ –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã")
#     #         break  # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–æ–≥—Ä–∞–º–º—É

# # –ó–∞–∫—Ä—ã–≤–∞–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω
# # stream.stop_stream()
# # stream.close()
# # mic.terminate()


